{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['image.cmap'] = \"gray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Non-Negative Matrix Factorization (NMF)\n",
    "![Alt text](http://cfile24.uf.tistory.com/image/990F9B405A3923AF21FB8F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NMF\n",
    "  - It is a group of algorithms where a matrix V is factorized into two matrices W and H, with the property that all three matrices have no negative elements. \n",
    "  - This non-negativity makes the resulting matrices easier to inspect.\n",
    "  - Also, in applications such as processing of audio spectrograms or muscular activity, non-negativity is inherent to the data being considered. Since the problem is not exactly solvable in general, it is commonly approximated numerically.\n",
    "  - 0 또는 양수로만 구성된 W와 H만을 생성\n",
    "  - W와 H의 각 원소가 음수가 아니므로 원 데이터의 특성에 음수가 없어야 함.\n",
    "  - https://en.wikipedia.org/wiki/Non-negative_matrix_factorization\n",
    "- NMF 활용 데이터\n",
    "  - 음성/악기 오디오 데이터\n",
    "  - 여러 악기 또는 음성이 섞여 있는 데이터에서 각 원본 성분들을 구분할 수 있음\n",
    "- PCA vs. NMF\n",
    "  - PCA\n",
    "    - 음수 성분이나 계수가 만드는 효과의 이해가 어려움. \n",
    "    - 실제로 부호에는 아무런 규칙이 없음\n",
    "  - NMF\n",
    "    - 상대적으로 PCA보다 해석하기 쉬움.\n",
    "    - 모든 주성분 사이에 원본 데이터의 특질을 더 많이 포함하는 중요도 차이가 없음 --> 즉 모든 주성분은 동등하게 중요\n",
    "    - W와 H의 무작위 초기화 --> 난수 생성 초기값에 따라 결과가 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying NMF to synthetic data\n",
    "- 원본 데이터 확인\n",
    "  - 원본 데이터의 각 성분이 양수인지 확인하는 작업 필요\n",
    "  - 각 데이터가 원점 (0,0)에서 상대적으로 어디에 놓여 있는가가 중요.\n",
    "  - 즉, 원점 (0,0)에서 데이터가 향하는 방향을 추출한 것으로서 음수미포함 성분 이해 가능<br/><br/>  \n",
    "\n",
    "- NMF 알고리즘\n",
    "  - $V$: 원본 데이터 행렬\n",
    "  - $W$: 새롭게 변환된 행렬\n",
    "  - $H$: 주성분 행렬\n",
    "  - the approximation of $V$ by $V \\simeq WH$ is achieved by minimizing the error function $$\\min_{W,H}|| V-WH ||_{F},~subject~to~W\\geq 0, H\\geq 0$$.\n",
    "  - 아래 논문을 활용하여 위와 같은 최적화 문제 해결\n",
    "    - Daniel D. Lee & H. Sebastian Seung (2001). Algorithms for Non-negative Matrix Factorization (PDF). Advances in Neural Information Processing Systems 13: Proceedings of the 2000 Conference. MIT Press. pp. 556–562.\n",
    "    - ![mnf](./images/mnf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_nmf_illustration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫번째 그래프\n",
    "  - 주성분 2개\n",
    "    - 데이터의 각 특성마다 끝에 위치한 포인트를 가리키는 방향으로 주성분 구성\n",
    "    - 총 100개의 원본 데이터: Shape (100, 2)에 대한 행렬 분해 결과\n",
    "      - V (100 x 2) = W (100 x 2) x H (2 x 2)\n",
    "  - 새롭게 변환된 특성 데이터: W (100 x 2)\n",
    "- 두번째 그래프\n",
    "  - 주성분 1개\n",
    "    - 데이터를 가장 잘 표현하는 각 특성마다 평균값으로 향하는 주성분을 구성\n",
    "    - 총 100개의 원본 데이터: Shape (100, 2)에 대한 행렬 분해 결과\n",
    "      - V (100 x 2) = W (100 x 1) x H (1 x 2)\n",
    "  - 새롭게 변환된 특성 데이터: W (100 x 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying NMF to face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_nmf_faces(X_train, X_test, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 데이터에 대한 비음수 분해: V = WH\n",
    "  - 원본 훈련 데이터 1,482개 V: Shape - (1486, 5655)\n",
    "  - 새롭게 변환된 행렬 W: Shape - (1486, 15)\n",
    "  - 주성분 데이터 H: Shape - (15, 5655)\n",
    "<br/>\n",
    "- 테스트 데이터에 대한 비음수 분해: V=WH\n",
    "  - 원본 테스트 데이터 494개 V: Shape - (494, 5655)\n",
    "  - 새롭게 변환된 행렬 W: Shape - (494, 15)\n",
    "  - 주성분 데이터 H: Shape - (15, 5655)\n",
    "<br/>  \n",
    "- [주의] 훈련 데이터에 대한 Fit 이후 테스트 데이터에 대한 Transform\n",
    "  - NMF는 Fit에 대한 의미없음\n",
    "    - https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/decomposition/nmf.py#L1246\n",
    "  - Transform 이 호출될 때 주어진 데이터에 대한 NMF 분해 시작하여 Transform의 반환값으로 W를 반환함.\n",
    "  - 즉, 비지도학습에 대해 훈련 데이터와 테스트 데이터를 구분하여 작업하는 것은 의미없음 (아래와 같은 코딩은 하면 안됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=15, random_state=0)\n",
    "nmf.fit(X_train)\n",
    "X_train_nmf = nmf.transform(X_train)\n",
    "X_test_nmf = nmf.transform(X_test)\n",
    "\n",
    "print(\"Transformed Train Data Shape:\", X_train_nmf.shape)\n",
    "print(\"Transformed Test Data Shape:\", X_test_nmf.shape)\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 12), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, (component, ax) in enumerate(zip(nmf.components_, axes.ravel())):\n",
    "    ax.imshow(component.reshape(image_shape))\n",
    "    ax.set_title(\"{}. component\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주성분 0~14 중 하나를 선택 --> compn 변수에 할당\n",
    "- NMF 알고리즘에 의하여 변환된 훈련 데이터: W (1486, 15)\n",
    "- 변환된 훈련 데이터의 각 특성중 compn 위치 값이 가장 큰 10개 선택하여 해당 10개에 대한 원본 데이터를 이미지 형태로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compn = 3\n",
    "# sort by 3rd component, plot first 10 images\n",
    "inds = np.argsort(X_train_nmf[:, compn])[::-1]\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "fig.suptitle(\"Large component 3\")\n",
    "for i, (ind, ax) in enumerate(zip(inds, axes.ravel())):\n",
    "    ax.imshow(X_train[ind].reshape(image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compn = 7\n",
    "# sort by 7th component, plot first 10 images\n",
    "inds = np.argsort(X_train_nmf[:, compn])[::-1]\n",
    "fig.suptitle(\"Large component 7\")\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, (ind, ax) in enumerate(zip(inds, axes.ravel())):\n",
    "    ax.imshow(X_train[ind].reshape(image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compn = 11\n",
    "# sort by 3rd component, plot first 10 images\n",
    "inds = np.argsort(X_train_nmf[:, compn])[::-1]\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8), subplot_kw={'xticks': (), 'yticks': ()})\n",
    "fig.suptitle(\"Large component 3\")\n",
    "for i, (ind, ax) in enumerate(zip(inds, axes.ravel())):\n",
    "    ax.imshow(X_train[ind].reshape(image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = mglearn.datasets.make_signals()\n",
    "print(\"Shape of S: {}\".format(S.shape))\n",
    "print(S[0][0])\n",
    "print(S[0][1])\n",
    "print(S[0][2])\n",
    "print()\n",
    "\n",
    "plt.figure(figsize=(6, 1))\n",
    "plt.plot(S, '-')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of S: {}\".format(S.shape))\n",
    "\n",
    "# Mix data into a 100 dimensional state\n",
    "A = np.random.RandomState(0).uniform(size=(100, 3))\n",
    "print(\"Shape of A: {}\".format(A.shape))\n",
    "print(A[0][0])\n",
    "print(A[0][1])\n",
    "print(A[0][2])\n",
    "print()\n",
    "print(A[1][0])\n",
    "print(A[1][1])\n",
    "print(A[1][2])\n",
    "print()\n",
    "\n",
    "X = np.dot(S, A.T)\n",
    "print(\"Shape of X (=S * A.T): {}\".format(X.shape))\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(X, '-', linewidth=1.0)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=3, random_state=42)\n",
    "S_ = nmf.fit_transform(X)\n",
    "print(\"NMF - Recovered signal shape: {}\".format(S_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "H = pca.fit_transform(X)\n",
    "print(\"PCA - Recovered signal shape: {}\".format(H.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [X, S, S_, H]\n",
    "names = ['Observations (first three measurements) - X: (2000, 100)',\n",
    "         'True sources - S: (2000, 3)',\n",
    "         'NMF recovered signals - S_: (2000, 3)',\n",
    "         'PCA recovered signals - H: (2000, 3)']\n",
    "\n",
    "fig, axes = plt.subplots(4, figsize=(8, 4), gridspec_kw={'hspace': .5}, subplot_kw={'xticks': (), 'yticks': ()})\n",
    "\n",
    "for model, name, ax in zip(models, names, axes):\n",
    "    ax.set_title(name)\n",
    "    ax.plot(model[:, :3], '-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
